{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# いい感じの関数をまとめていきましょう"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import skew\n",
    "from scipy.special import boxcox1p\n",
    "from scipy.stats import boxcox_normmax\n",
    "from scipy.stats import boxcox\n",
    "from scipy.special import inv_boxcox\n",
    "import matplotlib.pyplot as plt\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV, KFold,GridSearchCV\n",
    "from sklearn.metrics import r2_score,mean_absolute_error,mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler,RobustScaler,LabelEncoder,PowerTransformer\n",
    "from sklearn.ensemble import GradientBoostingRegressor,StackingRegressor, RandomForestRegressor, ExtraTreesRegressor\n",
    "from sklearn.linear_model import ElasticNet, Lasso, Ridge\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.decomposition import PCA\n",
    "import seaborn as sns  \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")         # for beautiful plots\n",
    "from scipy import stats                 # to calculate mode, skew and ANOVA, etc.\n",
    "import numpy as np # linear algebra\n",
    "np.set_printoptions(np.inf)\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm, skew #for some statistics\n",
    "plt.rcParams['figure.figsize'] = (10, 8)\n",
    "# importing alll the necessary packages to use the various classification algorithms\n",
    "from sklearn.linear_model import LogisticRegression  # for Logistic Regression algorithm\n",
    "from sklearn.model_selection import train_test_split #to split the dataset for training and testing\n",
    "from sklearn.neighbors import KNeighborsClassifier  # for K nearest neighbours\n",
    "from sklearn import svm  #for Support Vector Machine (SVM) Algorithm\n",
    "from sklearn import metrics #for checking the model accuracy\n",
    "from sklearn.metrics import mean_squared_error #for checking the model accuracy\n",
    "from sklearn.tree import DecisionTreeClassifier #for using Decision Tree Algoithm\n",
    "from sklearn.linear_model import ElasticNet, Lasso,  BayesianRidge, LassoLarsIC\n",
    "from sklearn.ensemble import RandomForestRegressor,  GradientBoostingRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "import time\n",
    "import pickle\n",
    "import gc\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 回帰問題のバリデーション設計"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_cv(model, train_x, train_y, test_x):\n",
    "    preds = []\n",
    "    preds_test = []\n",
    "    va_indexes = []\n",
    "    \n",
    "    kf = KFold(n_splits=4, shuffle=True, random_state=6785)\n",
    "    \n",
    "    # クロスバリデーションで学習・予測を行い、予測値とインデックスを保存する\n",
    "    for i, (tr_idx, va_idx) in enumerate(kf.split(train_x)):\n",
    "        tr_x, va_x = train_x.iloc[tr_idx], train_x.iloc[va_idx]\n",
    "        tr_y, va_y = train_y.iloc[tr_idx], train_y.iloc[va_idx]\n",
    "        model.fit(tr_x, tr_y)\n",
    "        tr_pred = model.predict(tr_x)\n",
    "        pred = model.predict(va_x)\n",
    "        preds.append(pred)\n",
    "        pred_test = model.predict(test_x)\n",
    "        preds_test.append(pred_test)\n",
    "        va_indexes.append(va_idx)\n",
    "        print('  score Train : {:.6f}' .format(np.sqrt(mean_squared_error(tr_y, tr_pred))), \n",
    "              '  score Valid : {:.6f}' .format(np.sqrt(mean_squared_error(va_y, pred)))) \n",
    "        \n",
    "    # バリデーションデータに対する予測値を連結し、その後元の順番に並べなおす\n",
    "    va_indexes = np.concatenate(va_indexes)\n",
    "    preds = np.concatenate(preds, axis=0)\n",
    "    order = np.argsort(va_indexes)\n",
    "    pred_train = pd.DataFrame(preds[order])\n",
    "    \n",
    "    \n",
    "    # テストデータに対する予測値の平均をとる\n",
    "    preds_test = pd.DataFrame(np.mean(preds_test, axis=0))\n",
    "    print('Score : {:.6f}' .format(np.sqrt(mean_squared_error(train_y, pred_train))))\n",
    "    return pred_train, preds_test, model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# メモリの削減"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df):\n",
    "    \"\"\" iterate through all the columns of a dataframe and modify the data type\n",
    "        to reduce memory usage.        \n",
    "    \"\"\"\n",
    "    start_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n",
    "    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "        \n",
    "        if col_type != object:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "        else:\n",
    "            df[col] = df[col].astype('category')\n",
    "\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n",
    "    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def import_data(file):\n",
    "    \"\"\"create a dataframe and optimize its memory usage\"\"\"\n",
    "    df = pd.read_csv(file, parse_dates=True, keep_date_col=True)\n",
    "    df = reduce_mem_usage(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ラベルエンコーディング"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "def label_encoding(train: pd.DataFrame, test: pd.DataFrame, col_definition: dict):\n",
    "    \"\"\"\n",
    "    col_definition: encode_col\n",
    "    \"\"\"\n",
    "    n_train = len(train)\n",
    "    train = data\n",
    "    for f in col_definition['encode_col']:\n",
    "        try:\n",
    "            lbl = preprocessing.LabelEncoder()\n",
    "            train[f] = lbl.fit_transform(list(train[f].values))\n",
    "        except:\n",
    "            print(f)\n",
    "    test = train[n_train:].reset_index(drop=True)\n",
    "    train = train[:n_train]\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# overfit reduser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overfit_reducer(df):\n",
    "\n",
    "    overfit = []\n",
    "    for i in df.columns:\n",
    "        counts = df[i].value_counts()\n",
    "        zeros = counts.iloc[0]\n",
    "        if zeros / len(df) * 100 > 99.9:\n",
    "            overfit.append(i)\n",
    "    overfit = list(overfit)\n",
    "    return overfit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds = []\n",
    "models = []\n",
    "oof_train = np.zeros((len(X_train),))\n",
    "cv = KFold(n_splits=3, shuffle=True, random_state=1156)\n",
    "\n",
    "params = {'objective':'regression',\n",
    "          'metric': 'rmse',\n",
    "          'num_leaves':3,\n",
    "          'learning_rate':0.05,\n",
    "          'n_estimators':720,\n",
    "          'max_bin' : 300, \n",
    "          'bagging_fraction' : 0.8,\n",
    "          'bagging_freq' : 5, \n",
    "          'feature_fraction' : 0.2319,\n",
    "          'feature_fraction_seed':9, \n",
    "          'bagging_seed':9,\n",
    "          'min_data_in_leaf' :20, \n",
    "          'min_sum_hessian_in_leaf' : 11,\n",
    "          'importance_type': 'gain'\n",
    "}\n",
    "\n",
    "feature_importance_df = pd.DataFrame()\n",
    "col = list(X_train.columns)\n",
    "i = 1\n",
    "feat_df = pd.DataFrame()\n",
    "\n",
    "for fold_id, (train_index, valid_index) in enumerate(cv.split(X_train)):\n",
    "    X_tr = X_train.loc[train_index, :]\n",
    "    X_val = X_train.loc[valid_index, :]\n",
    "    y_tr = y_train[train_index]\n",
    "    y_val = y_train[valid_index]\n",
    "\n",
    "    lgb_train = lgb.Dataset(X_tr,\n",
    "                            y_tr,\n",
    "                            categorical_feature=categorical_cols)\n",
    "\n",
    "    lgb_eval = lgb.Dataset(X_val,\n",
    "                           y_val,\n",
    "                           reference=lgb_train,\n",
    "                           categorical_feature=categorical_cols)\n",
    "\n",
    "    model = lgb.train(params,\n",
    "                      lgb_train,\n",
    "                      valid_sets=[lgb_train, lgb_eval],\n",
    "                      verbose_eval=100,\n",
    "                      num_boost_round=1000,\n",
    "                      early_stopping_rounds=4)\n",
    "\n",
    "    fold_feat_df = pd.DataFrame()\n",
    "    fold_feat_df[\"Feature_fold{}\".format(i)] = col\n",
    "    fold_feat_df[\"Importance_fold{}\".format(i)] = model.feature_importance()\n",
    "    i += 1\n",
    "    feat_df = pd.concat([feat_df, fold_feat_df], axis=1)\n",
    "    \n",
    "    oof_train[valid_index] = model.predict(X_val,\n",
    "                                           num_iteration=model.best_iteration)\n",
    "    y_pred = model.predict(X_test,\n",
    "                           num_iteration=model.best_iteration)\n",
    "\n",
    "    y_preds.append(y_pred)\n",
    "    models.append(model)\n",
    "print(f'CV: {np.sqrt(mean_squared_error(y_train, oof_train))}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 上記のLGBMのImportanceの可視化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_importance_plot(df):\n",
    "    a = df[[\"Feature_fold1\",\"Importance_fold1\"]]\n",
    "    b = df[[\"Feature_fold2\",\"Importance_fold2\"]].rename(columns={\"Feature_fold2\":\"Feature_fold1\", \"Importance_fold2\":\"Importance_fold1\"})\n",
    "    c = df[[\"Feature_fold3\",\"Importance_fold3\"]].rename(columns={\"Feature_fold3\":\"Feature_fold1\", \"Importance_fold3\":\"Importance_fold1\"})\n",
    "    d = df[[\"Feature_fold4\",\"Importance_fold4\"]].rename(columns={\"Feature_fold4\":\"Feature_fold1\", \"Importance_fold4\":\"Importance_fold1\"})\n",
    "    e = df[[\"Feature_fold5\",\"Importance_fold5\"]].rename(columns={\"Feature_fold5\":\"Feature_fold1\", \"Importance_fold5\":\"Importance_fold1\"})\n",
    "    \n",
    "    feat = pd.concat([a, b, c, d]).reset_index()\n",
    "    indices = feat.groupby(\"Feature_fold1\")[\"Importance_fold1\"].agg(\"mean\").reset_index().sort_values(\"Importance_fold1\", ascending=False)[[\"Feature_fold1\",'Importance_fold1']]\n",
    "    plt.figure(figsize=(10,14))\n",
    "    plt.title(\"重要度上位50\")\n",
    "    sns.barplot(x=\"Importance_fold1\", y=\"Feature_fold1\", data=feat, order=indices.iloc[:50, 0])\n",
    "    return indices\n",
    "indices = feature_importance_plot(feat_df)\n",
    "# indicesでimportanceをDataFrameで返す"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2値分類"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "sampler = RandomUnderSampler(random_state=42)\n",
    "def predict_cv(model, train_x, train_y, test_x):\n",
    "    preds = []\n",
    "    preds_test = []\n",
    "    va_indexes = []\n",
    "    train_score = []\n",
    "    \n",
    "    kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=6785)\n",
    "    \n",
    "    feature_importance_df = pd.DataFrame()\n",
    "    col = list(train_x.columns)\n",
    "    i = 1\n",
    "    feat_df = pd.DataFrame()\n",
    "    \n",
    "    # クロスバリデーションで学習・予測を行い、予測値とインデックスを保存する\n",
    "    for i, (tr_idx, va_idx) in enumerate(kf.split(train_x, train_y)):\n",
    "        tr_x, va_x = train_x.iloc[tr_idx], train_x.iloc[va_idx]\n",
    "        tr_y, va_y = train_y.iloc[tr_idx], train_y.iloc[va_idx]\n",
    "        \n",
    "        \n",
    "        model.fit(tr_x, tr_y, \n",
    "                  eval_set= [(tr_x, tr_y), (va_x, va_y)],\n",
    "                  eval_metric='auc',\n",
    "                  verbose=1000, \n",
    "                  early_stopping_rounds=20)\n",
    "        \n",
    "        \n",
    "        tr_pred = model.predict_proba(tr_x)[:, 1]\n",
    "        pred = model.predict_proba(va_x)[:, 1]\n",
    "        preds.append(pred)\n",
    "        pred_test = model.predict_proba(test_x)[:, 1]\n",
    "        preds_test.append(pred_test)\n",
    "        va_indexes.append(va_idx)\n",
    "        \n",
    "        fold_feat_df = pd.DataFrame()\n",
    "        fold_feat_df[\"Feature_fold{}\".format(i)] = col\n",
    "        fold_feat_df[\"Importance_fold{}\".format(i)] = model.feature_importances_\n",
    "        i += 1\n",
    "        feat_df = pd.concat([feat_df, fold_feat_df], axis=1)\n",
    "        print('  score Train : {:.6f}' .format(roc_auc_score(tr_y, tr_pred)), \n",
    "              '  score Valid : {:.6f}' .format(roc_auc_score(va_y, pred)))\n",
    "        train_score.append(roc_auc_score(tr_y, tr_pred))\n",
    "        \n",
    "    # バリデーションデータに対する予測値を連結し、その後元の順番に並べなおす\n",
    "    va_indexes = np.concatenate(va_indexes)\n",
    "    preds = np.concatenate(preds, axis=0)\n",
    "    order = np.argsort(va_indexes)\n",
    "    pred_train = pd.DataFrame(preds[order])\n",
    "    \n",
    "    \n",
    "    # テストデータに対する予測値の平均をとる\n",
    "    preds_test = pd.DataFrame(np.mean(preds_test, axis=0))\n",
    "    print('*'*40)\n",
    "    print('train Score : {:.6f}' .format(np.mean(train_score)))\n",
    "    print('valid Score : {:.6f}' .format(roc_auc_score(train_y, pred_train)))\n",
    "    print('train Score - valid Score : {:.6f}'.format(np.mean(train_score) - roc_auc_score(train_y, pred_train)))\n",
    "    return pred_train, preds_test, model, feat_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_importance_plot(df):\n",
    "    a = df[[\"Feature_fold0\",\"Importance_fold0\"]]\n",
    "    b = df[[\"Feature_fold1\",\"Importance_fold1\"]].rename(columns={\"Feature_fold1\":\"Feature_fold0\", \"Importance_fold1\":\"Importance_fold0\"})\n",
    "    c = df[[\"Feature_fold2\",\"Importance_fold2\"]].rename(columns={\"Feature_fold2\":\"Feature_fold0\", \"Importance_fold2\":\"Importance_fold0\"})\n",
    "    d = df[[\"Feature_fold3\",\"Importance_fold3\"]].rename(columns={\"Feature_fold3\":\"Feature_fold0\", \"Importance_fold3\":\"Importance_fold0\"})\n",
    "    e = df[[\"Feature_fold4\",\"Importance_fold4\"]].rename(columns={\"Feature_fold4\":\"Feature_fold0\", \"Importance_fold4\":\"Importance_fold0\"})\n",
    "    \n",
    "    feat = pd.concat([a, b, c, d, e]).reset_index()\n",
    "    indices = feat.groupby(\"Feature_fold0\")[\"Importance_fold0\"].agg(\"mean\").reset_index().sort_values(\"Importance_fold0\", ascending=False)[[\"Feature_fold0\",'Importance_fold0']]\n",
    "    plt.figure(figsize=(10,14))\n",
    "    plt.title(\"Top50\")\n",
    "    sns.barplot(x=\"Importance_fold0\", y=\"Feature_fold0\", data=feat, order=indices.iloc[:50, 0])\n",
    "    return indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optuna(LGBM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'objective': 'regression',\n",
    "        'metric': 'rmse',\n",
    "        'max_depth': trial.suggest_int('max_depth', 2, 16),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 2, 32),\n",
    "        'learning_rate': trial.suggest_int('num_leaves', 2, 32),\n",
    "        'feature_fraction': trial.suggest_uniform('feature_fraction', 0.4, 1.0),\n",
    "        'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.4, 1.0),\n",
    "        'feature_fraction_seed': trial.suggest_int('feature_fraction_seed', 0, 10), \n",
    "        'bagging_seed': trial.suggest_int('bagging_seed', 0, 10), \n",
    "        'max_bin': trial.suggest_int('max_bin', 80, 500),\n",
    "        'min_data_in_leaf': trial.suggest_int('min_data_in_leaf', 20, 80),\n",
    "        'importance_type': 'gain'\n",
    "    }\n",
    "            \n",
    "    for fold_id, (train_index, valid_index) in enumerate(cv.split(X_train)):\n",
    "        X_tr = X_train.loc[train_index, :]\n",
    "        X_val = X_train.loc[valid_index, :]\n",
    "        y_tr = y_train[train_index]\n",
    "        y_val = y_train[valid_index]\n",
    "\n",
    "        lgb_train = lgb.Dataset(X_tr,\n",
    "                                y_tr,\n",
    "                                categorical_feature=categorical_cols)\n",
    "\n",
    "        lgb_eval = lgb.Dataset(X_val,\n",
    "                               y_val,\n",
    "                               reference=lgb_train,\n",
    "                               categorical_feature=categorical_cols)\n",
    "\n",
    "        model = lgb.train(params,\n",
    "                          lgb_train,\n",
    "                          valid_sets=[lgb_train, lgb_eval],\n",
    "                          verbose_eval=10,\n",
    "                          num_boost_round=1000,\n",
    "                          early_stopping_rounds=10)\n",
    "\n",
    "\n",
    "        oof_train[valid_index] = model.predict(X_val,\n",
    "                                               num_iteration=model.best_iteration)\n",
    "        y_pred = model.predict(X_test,\n",
    "                               num_iteration=model.best_iteration)\n",
    "\n",
    "        y_preds.append(y_pred)\n",
    "        models.append(model)\n",
    "     \n",
    "    score = np.sqrt(mean_squared_error(y_train, oof_train))\n",
    "    return score   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2020-08-11 14:51:12,405] Trial 0 failed because of the following error: NameError(\"name 'cv' is not defined\")\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\koyo\\anaconda3\\lib\\site-packages\\optuna\\study.py\", line 709, in _run_trial\n",
      "    result = func(trial)\n",
      "  File \"<ipython-input-13-45d24dd954dc>\", line 20, in objective\n",
      "    for fold_id, (train_index, valid_index) in enumerate(cv.split(X_train)):\n",
      "NameError: name 'cv' is not defined\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'cv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-3b3e7a317f0b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mstudy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptuna\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_study\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msampler\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptuna\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msamplers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRandomSampler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mstudy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mstudy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_params\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\optuna\\study.py\u001b[0m in \u001b[0;36moptimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    289\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    290\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 291\u001b[1;33m                 self._optimize_sequential(\n\u001b[0m\u001b[0;32m    292\u001b[0m                     \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_trials\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgc_after_trial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    293\u001b[0m                 )\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\optuna\\study.py\u001b[0m in \u001b[0;36m_optimize_sequential\u001b[1;34m(self, func, n_trials, timeout, catch, callbacks, gc_after_trial, time_start)\u001b[0m\n\u001b[0;32m    652\u001b[0m                     \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    653\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 654\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_trial_and_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgc_after_trial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    655\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    656\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_progress_bar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mtime_start\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtotal_seconds\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\optuna\\study.py\u001b[0m in \u001b[0;36m_run_trial_and_callbacks\u001b[1;34m(self, func, catch, callbacks, gc_after_trial)\u001b[0m\n\u001b[0;32m    683\u001b[0m         \u001b[1;31m# type: (...) -> None\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    684\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 685\u001b[1;33m         \u001b[0mtrial\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_trial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgc_after_trial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    686\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    687\u001b[0m             \u001b[0mfrozen_trial\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_storage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_trial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_trial_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\optuna\\study.py\u001b[0m in \u001b[0;36m_run_trial\u001b[1;34m(self, func, catch, gc_after_trial)\u001b[0m\n\u001b[0;32m    707\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    708\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 709\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    710\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrialPruned\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    711\u001b[0m             \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Trial {} pruned. {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial_number\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-13-45d24dd954dc>\u001b[0m in \u001b[0;36mobjective\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m     18\u001b[0m     }\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mfold_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_index\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m         \u001b[0mX_tr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrain_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[0mX_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mvalid_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cv' is not defined"
     ]
    }
   ],
   "source": [
    "ts = time.time()\n",
    "study = optuna.create_study(sampler=optuna.samplers.RandomSampler())\n",
    "study.optimize(objective, n_trials=200)\n",
    "study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.183749198913574"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time.time() - ts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 加重平均の重みづけ最適化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "best_pram_score = []\n",
    "scores = []\n",
    "for i in np.arange(0, 1, 0.1):\n",
    "    for j in np.arange(0, 1-i, 0.1):\n",
    "        for k in np.arange(0, 1-(i+j), 0.1):\n",
    "            for l in np.arange(0, 1-(i+j+k), 0.1):\n",
    "                m = 1-(i+j+k+l)\n",
    "                train_pred = i*lgbm_pred_train + j*elastic_pred_train + k*ridge_pred_train + l*lasso_pred_train + m*stack_pred_train\n",
    "                score = np.sqrt(mean_squared_error(y, train_pred))\n",
    "                best_pram_score.append([score, train_pred, i,j,k,l,m])\n",
    "\n",
    "best_param_score = pd.DataFrame(best_pram_score)\n",
    "best_param_score.columns = ['score', 'df', 'LGBM', 'eNet', 'Ridge', 'Lasso', 'Stack']\n",
    "best_param = best_param_score[best_param_score['score'] == best_param_score['score'].min()]\n",
    "i,j,k,l,m = best_param.iat[0, 2], best_param.iat[0, 3], best_param.iat[0, 4], best_param.iat[0, 5], best_param.iat[0,6]\n",
    "best_param"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# とりあえず可視化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def first_eda(df):\n",
    "    num = [f for f in df.columns if df.dtypes[f] != 'object']\n",
    "    cat = [f for f in df.columns if df.dtypes[f] == 'object']\n",
    "    \n",
    "    for n in num:\n",
    "        sns.distplot(df[n])\n",
    "        plt.show()\n",
    "    \n",
    "    for c in cat:\n",
    "        sns.countplot(c, data=df)\n",
    "        plt.xticks(rotation=90)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数値変数とカテゴリ変数に分ける"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def num_cat(df):\n",
    "    num_f = df.dtypes[df.dtypes != 'object'].index\n",
    "    cat_f = df.dtypes[df.dtypes == 'object'].index\n",
    "    return num_f, cat_f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# カテゴリ変数の可視化（分類問題）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_bar(df, col):\n",
    "    df_tmp = df[col][df.TARGET==0].value_counts()\n",
    "    df1 = pd.DataFrame({col: df_tmp.index,'Count TARGET=0': df_tmp.values})\n",
    "    df_tmp = df[col][df.TARGET==1].value_counts()\n",
    "    df2 = pd.DataFrame({col: df_tmp.index,'Count TARGET=1': df_tmp.values})\n",
    "    fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(15,8))\n",
    "    p1 = sns.barplot(ax=ax1, x = col, y=\"Count TARGET=0\",data=df1)\n",
    "    p1.set_xticklabels(p1.get_xticklabels(),rotation=90)\n",
    "    p2 = sns.barplot(ax=ax2, x = col, y=\"Count TARGET=1\",data=df2)\n",
    "    p2.set_xticklabels(p2.get_xticklabels(),rotation=90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数値変数の可視化（分類問題）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_dist(df, col):\n",
    "    for i in [(0,'g'),(1,'y')]:\n",
    "        plt.figure(figsize=(12,5))\n",
    "        plt.title(\"Distribution of \"+ col +\" wrt Target = \"+str(i[0]))\n",
    "        ax = sns.distplot(df[col][df.TARGET==i[0]].dropna(), color=i[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 母比率の差の検定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bohiritsu_test(table):\n",
    "    n_ehf = table.iloc[0, 0] + table.iloc[1, 0]\n",
    "    x_ehf = table.iloc[1, 0]\n",
    "    n_japan = table.iloc[0, 1] + table.iloc[1, 1]\n",
    "    x_japan = table.iloc[1, 1]\n",
    "    p_ehf = x_ehf / n_ehf\n",
    "    p_japan = x_japan / n_japan\n",
    "    p_hat = (n_ehf*p_ehf + n_japan*p_japan) / (n_ehf + n_japan)\n",
    "\n",
    "    z = (p_ehf - p_japan) / math.sqrt(p_hat*(1-p_hat)*(1/n_ehf+1/n_japan))\n",
    "    print('母比率の差の統計検定量=',z)\n",
    "    alpha = 0.05 # 有意水準\n",
    "    z_value = stats.norm.ppf(1-alpha)\n",
    "\n",
    "    if z < z_value:\n",
    "        print('有意差なし')\n",
    "    else:\n",
    "        print('有意差あり')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ターゲット別のKDEを見る（2値分類）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_col = 'bureau_DAYS_CREDIT_mean'\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.distplot(application_train.loc[(application_train['TARGET'] == 0), temp_col], bins=100, label='repay(0)', color='r')\n",
    "sns.distplot(application_train.loc[(application_train['TARGET'] == 1), temp_col], bins=100, label='not repay(1)', color='b')\n",
    "plt.title('Distplot for {} splitted by target'.format(temp_col))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LGBMに突っ込む際に正規表現にする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def rename_data(df):\n",
    "    df = df.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "    return df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
